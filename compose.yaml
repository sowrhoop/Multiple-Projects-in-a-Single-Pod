version: "3.8"

services:
  service-a:
    build: ./services/service-a
    image: your-dockerhub-username/service-a:latest
    environment:
      - PORT=8080
      - NODE_ENV=production
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/ || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    # Hardened container runtime
    read_only: true
    tmpfs:
      - /tmp
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    ulimits:
      nproc: 256
      nofile:
        soft: 1024
        hard: 2048
    restart: unless-stopped
    networks:
      - backend
    # GPU for local compose (if needed):
    # device_requests:
    #   - driver: nvidia
    #     count: 1
    #     capabilities: ["gpu"]

  service-b:
    build: ./services/service-b
    image: your-dockerhub-username/service-b:latest
    environment:
      - PORT=9090
      - NODE_ENV=production
      - SERVICE_A_URL=http://service-a:8080
    ports:
      - "9090:9090"
    depends_on:
      service-a:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:9090/ || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    # Hardened container runtime
    read_only: true
    tmpfs:
      - /tmp
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    ulimits:
      nproc: 256
      nofile:
        soft: 1024
        hard: 2048
    restart: unless-stopped
    networks:
      - backend
    # GPU for local compose (if needed):
    # device_requests:
    #   - driver: nvidia
    #     count: 1
    #     capabilities: ["gpu"]

networks:
  backend:
    internal: true
